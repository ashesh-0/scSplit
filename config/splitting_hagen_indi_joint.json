{
    "name": "splitting",
    "phase": "train", // train or val
    "gpu_ids": [
        0
    ],
    "path": { //set the path
        "root": "/group/jug/ashesh/training/diffSplit/",
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": null
        // "resume_state": "experiments/distributed_high_sr_ffhq_210901_121212/checkpoint/I830000_E32" //pretrain model or training state
    },
    "datasets": {
        "upper_clip": false,
        "patch_size": 512,
        "max_qval": 1.0,
        "normalize_channels": false,
        // "channel_weights": [1.0, 1.0],
        "train": {
            "name": "Hagen",
            "datapath": {
                "ch0": "/group/jug/ashesh/data/diffsplit_hagen/train/train_actin-60x-noise2-highsnr.tif",
                "ch1": "/group/jug/ashesh/data/diffsplit_hagen/train/train_mito-60x-noise2-highsnr.tif"
            },
            "datatype": "img", //lmdb or img, path of img files
            "batch_size": 8,
            "num_workers": 4,
            "use_shuffle": true,
            "uncorrelated_channels": false
        },
        "val": {
            "name": "Hagen",
            // "target_channel_idx": 0, // If set then we do image translation from input to this channel 
            "datapath": {
                "ch0": "/group/jug/ashesh/data/diffsplit_hagen/val/val_actin-60x-noise2-highsnr.tif",
                "ch1": "/group/jug/ashesh/data/diffsplit_hagen/val/val_mito-60x-noise2-highsnr.tif"
            },
            "patch_size": 512,
            "datatype": "img" //lmdb or img, path of img files
        }
    },
    "model": {
        "which_model_G": "joint_indi", // use the ddpm or sr3 network structure
        "loss_type": "l1", // TODO: this is not used now, but will be used in future to test mutliple loss functions
        "w_input_loss": 0.1,
        "lr_reduction": "mean",
        "unsupervised_arithmetic": false,
        "normalize_xt": true,
        "finetune_norm": false,
        "allow_full_translation": true, // t is sampled between [0,1] if this is True.
        "enable_time_predictor": false,
        "unet": {
            "in_channel": 1, // target channel + input channel. it is so because the noise of the shape target is concatenated with the input
            "out_channel": 1,
            "inner_channel": 16,
            "norm_groups": 16,
            "initial_instance_norm": true, // if true then before anything, instance norm is applied. 
            "channel_multiplier": [
                1,
                2,
                4,
                8
                // 8
                // 16,
                // 16
            ],
            "attn_res": [
                // 16
            ],
            "res_blocks": 1,
            "dropout": 0.1
        },
        "beta_schedule": { // use munual beta_schedule for acceleration
            "train": {
                "schedule": "linear",
                "n_timestep": 2000,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            },
            "val": {
                "schedule": "linear",
                "n_timestep": 1,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            }
        },
        "diffusion": {
            "image_size": 32,
            "channels": 1, //sample channel
            "conditional": false // unconditional generation or unconditional generation(super_resolution)
        }
    },
    "train": {
        "n_iter": 1000000,
        "val_freq": 1e4,
        "save_checkpoint_freq": 1e4,
        "print_freq": 500,
        "optimizer": {
            "type": "adam",
            "lr": 1e-3
            
        },
        "lr_scheduler": {
            "patience": 100
            // "step_start_ema": 5000,
            // "update_ema_every": 1,
            // "ema_decay": 0.9999
        }
    },
    "wandb": {
        "project": "DiffSplit"
    }
}